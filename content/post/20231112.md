---
author: "Yukara Ikemiya"
authorAvatar: img/yukara_profile.jpg

date: 2023-12-03
title: Best Practices for Multi-Node Training on ABCI with PyTorch
linktitle: Best Practices for Multi-Node Training on ABCI
image: post/img/20220917/painting_robot.jpg

tags : [
    "ai", "deep learning"
]
categories : [
    "Technology"
]

weight: 10
draft: true
---

This article summarizes a simple method for conducting distributed training with ABCI which is the GPU cloud computing service by AIST. 

# Let's use ABCI for training large-scale models

> AI Bridging Cloud Infrastructure (ABCI) is the world's first large-scale Open AI Computing Infrastructure, constructed and operated by National Institute of Advanced Industrial Science and Technology (AIST).
(https://abci.ai/en/about_abci/)

&rarr;  [How to use ABCI](https://abci.ai/en/how_to_use/)

# Create a Python environment

ABCI supports the use of [Singularity](https://docs.sylabs.io/guides/3.0/user-guide/quick_start.html) containers for building learning environments. There are several ways to build a Singularity container (SIF), but in my repository, scripts are provided for creating a Docker image first and then converting that image into a SIF file.

Once a SIF file is created, move it to any directory on ABCI and use it for running your training.

# Prepare training codes

When conducting distributed training with PyTorch, it is common to write training codes using DistributedDataParallel (DDP). However, here, it is recommended to utilize [HuggingFace Accelerate](https://huggingface.co/docs/accelerate/index), which wraps DDP, allowing for a more straightforward implementation. This not only simplifies the codes but also helps prevent the introduction of potential bugs.

[HuggingFace Accelerate](https://huggingface.co/docs/accelerate/index)

```python
python
```